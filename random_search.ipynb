{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOmqmbfOu5+GbC7S9wmDdSo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alicepearse/DL_prac/blob/master/random_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXK3HPnJ8Pwi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbL94Duf9jfH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import theano\n",
        "import theano.tensor as T\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "def init_weight(M1, M2):\n",
        "  return np.random.randn(M1, M2) * np.sqrt(2.0 / M1)\n",
        "\n",
        "\n",
        "class HiddenLayer(object):\n",
        "    def __init__(self, M1, M2, f):\n",
        "        self.M1 = M1\n",
        "        self.M2 = M2\n",
        "        self.f = f\n",
        "        W = init_weight(M1, M2)\n",
        "        b = np.zeros(M2)\n",
        "        self.W = theano.shared(W)\n",
        "        self.b = theano.shared(b)\n",
        "        self.params = [self.W, self.b]\n",
        "\n",
        "    def forward(self, X):\n",
        "        if self.f == T.nnet.relu:\n",
        "            return self.f(X.dot(self.W) + self.b, alpha=0.1)\n",
        "        return self.f(X.dot(self.W) + self.b)\n",
        "\n",
        "\n",
        "class ANN(object):\n",
        "    def __init__(self, hidden_layer_sizes):\n",
        "        self.hidden_layer_sizes = hidden_layer_sizes\n",
        "\n",
        "    def fit(self, X, Y, activation=T.nnet.relu, learning_rate=1e-3, mu=0.0, reg=0, epochs=100, batch_sz=None, print_period=100, show_fig=True):\n",
        "        X = X.astype(np.float32)\n",
        "        Y = Y.astype(np.int32)\n",
        "\n",
        "        # initialize hidden layers\n",
        "        N, D = X.shape\n",
        "        self.layers = []\n",
        "        M1 = D\n",
        "        for M2 in self.hidden_layer_sizes:\n",
        "            h = HiddenLayer(M1, M2, activation)\n",
        "            self.layers.append(h)\n",
        "            M1 = M2\n",
        "        \n",
        "        # final layer\n",
        "        K = len(set(Y))\n",
        "        # print(\"K:\", K)\n",
        "        h = HiddenLayer(M1, K, T.nnet.softmax)\n",
        "        self.layers.append(h)\n",
        "\n",
        "        if batch_sz is None:\n",
        "            batch_sz = N\n",
        "\n",
        "        # collect params for later use\n",
        "        self.params = []\n",
        "        for h in self.layers:\n",
        "            self.params += h.params\n",
        "\n",
        "        # for momentum\n",
        "        dparams = [theano.shared(np.zeros_like(p.get_value())) for p in self.params]\n",
        "\n",
        "        # set up theano functions and variables\n",
        "        thX = T.matrix('X')\n",
        "        thY = T.ivector('Y')\n",
        "        p_y_given_x = self.forward(thX)\n",
        "\n",
        "        rcost = reg*T.mean([(p*p).sum() for p in self.params])\n",
        "        cost = -T.mean(T.log(p_y_given_x[T.arange(thY.shape[0]), thY])) #+ rcost\n",
        "        prediction = T.argmax(p_y_given_x, axis=1)\n",
        "        grads = T.grad(cost, self.params)\n",
        "\n",
        "        # momentum only\n",
        "        updates = [\n",
        "            (p, p + mu*dp - learning_rate*g) for p, dp, g in zip(self.params, dparams, grads)\n",
        "        ] + [\n",
        "            (dp, mu*dp - learning_rate*g) for dp, g in zip(dparams, grads)\n",
        "        ]\n",
        "\n",
        "        train_op = theano.function(\n",
        "            inputs=[thX, thY],\n",
        "            outputs=[cost, prediction],\n",
        "            updates=updates,\n",
        "        )\n",
        "\n",
        "        self.predict_op = theano.function(\n",
        "            inputs=[thX],\n",
        "            outputs=prediction,\n",
        "        )\n",
        "\n",
        "        n_batches = N // batch_sz\n",
        "        costs = []\n",
        "        for i in range(epochs):\n",
        "            if n_batches > 1:\n",
        "              X, Y = shuffle(X, Y)\n",
        "            for j in range(n_batches):\n",
        "                Xbatch = X[j*batch_sz:(j*batch_sz+batch_sz)]\n",
        "                Ybatch = Y[j*batch_sz:(j*batch_sz+batch_sz)]\n",
        "\n",
        "                c, p = train_op(Xbatch, Ybatch)\n",
        "                costs.append(c)\n",
        "                if (j+1) % print_period == 0:\n",
        "                    print(\"i:\", i, \"j:\", j, \"nb:\", n_batches, \"cost:\", c)\n",
        "        \n",
        "        if show_fig:\n",
        "            plt.plot(costs)\n",
        "            plt.show()\n",
        "\n",
        "    def forward(self, X):\n",
        "        out = X\n",
        "        for h in self.layers:\n",
        "            out = h.forward(out)\n",
        "        return out\n",
        "\n",
        "    def score(self, X, Y):\n",
        "        P = self.predict_op(X)\n",
        "        return np.mean(Y == P)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.predict_op(X)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnuWuNW49vfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "def get_clouds():\n",
        "    Nclass = 500\n",
        "    D = 2\n",
        "\n",
        "    X1 = np.random.randn(Nclass, D) + np.array([0, -2])\n",
        "    X2 = np.random.randn(Nclass, D) + np.array([2, 2])\n",
        "    X3 = np.random.randn(Nclass, D) + np.array([-2, 2])\n",
        "    X = np.vstack([X1, X2, X3])\n",
        "\n",
        "    Y = np.array([0]*Nclass + [1]*Nclass + [2]*Nclass)\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def get_spiral():\n",
        "    # Idea: radius -> low...high\n",
        "    #           (don't start at 0, otherwise points will be \"mushed\" at origin)\n",
        "    #       angle = low...high proportional to radius\n",
        "    #               [0, 2pi/6, 4pi/6, ..., 10pi/6] --> [pi/2, pi/3 + pi/2, ..., ]\n",
        "    # x = rcos(theta), y = rsin(theta) as usual\n",
        "\n",
        "    radius = np.linspace(1, 10, 100)\n",
        "    thetas = np.empty((6, 100))\n",
        "    for i in range(6):\n",
        "        start_angle = np.pi*i / 3.0\n",
        "        end_angle = start_angle + np.pi / 2\n",
        "        points = np.linspace(start_angle, end_angle, 100)\n",
        "        thetas[i] = points\n",
        "\n",
        "    # convert into cartesian coordinates\n",
        "    x1 = np.empty((6, 100))\n",
        "    x2 = np.empty((6, 100))\n",
        "    for i in range(6):\n",
        "        x1[i] = radius * np.cos(thetas[i])\n",
        "        x2[i] = radius * np.sin(thetas[i])\n",
        "\n",
        "    # inputs\n",
        "    X = np.empty((600, 2))\n",
        "    X[:,0] = x1.flatten()\n",
        "    X[:,1] = x2.flatten()\n",
        "\n",
        "    # add noise\n",
        "    X += np.random.randn(600, 2)*0.5\n",
        "\n",
        "    # targets\n",
        "    Y = np.array([0]*100 + [1]*100 + [0]*100 + [1]*100 + [0]*100 + [1]*100)\n",
        "    return X, Y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD2XYrYT916I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_search():\n",
        "  # get the data and split into train/test\n",
        "  X, Y = get_spiral()\n",
        "  # X, Y = get_clouds()\n",
        "  X, Y = shuffle(X, Y)\n",
        "  Ntrain = int(0.7*len(X))\n",
        "  Xtrain, Ytrain = X[:Ntrain], Y[:Ntrain]\n",
        "  Xtest, Ytest = X[Ntrain:], Y[Ntrain:]\n",
        "\n",
        "  # starting hyperparameters\n",
        "  M = 20\n",
        "  nHidden = 2\n",
        "  log_lr = -4\n",
        "  log_l2 = -2 # since we always want it to be positive\n",
        "  max_tries = 30\n",
        "\n",
        "  # loop through all possible hyperparameter settings\n",
        "  best_validation_rate = 0\n",
        "  best_hls = None\n",
        "  best_lr = None\n",
        "  best_l2 = None\n",
        "  for _ in range(max_tries):\n",
        "    model = ANN([M]*nHidden)\n",
        "    model.fit(\n",
        "        Xtrain, Ytrain,\n",
        "        learning_rate = 10**log_lr, reg=10**log_l2,\n",
        "        mu = 0.99, epochs = 3000, show_fig = False\n",
        "    )\n",
        "    validation_accuracy = model.score(Xtest, Ytest)\n",
        "    train_accuracy = model.score(Xtrain, Ytrain)\n",
        "    print(\n",
        "        \"validation_accuracy: %.3f, train_accuracy: %.3f, settings: %s, %s, %s\" %\n",
        "        (validation_accuracy, train_accuracy, [M]*nHidden, log_lr, log_l2)\n",
        "    )\n",
        "    if validation_accuracy > best_validation_rate:\n",
        "      best_validation_rate = validation_accuracy\n",
        "      best_M = M\n",
        "      best_nHidden = nHidden\n",
        "      best_lr = log_lr\n",
        "      best_l2 = log_l2\n",
        "\n",
        "    # select new hyperparams\n",
        "    nHidden = best_nHidden + np.random.randint(-1, 2) # -1, 0, or 1\n",
        "    nHidden = max(1, nHidden)\n",
        "    M = best_M + np.random.randint(-1, 2)*10\n",
        "    M = max(10, M)\n",
        "    log_lr = best_lr + np.random.randint(-1, 2)\n",
        "    log_l2 = best_l2 + np.random.randint(-1, 2)\n",
        "  print(\"Best validation_accuracy:\", best_validation_rate)\n",
        "  print(\"Best settings:\")\n",
        "  print(\"best_M:\", best_M)\n",
        "  print(\"best_nHidden:\", best_nHidden)\n",
        "  print(\"learning_rate:\", best_lr)\n",
        "  print(\"l2:\", best_l2)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wevvm-eIHGkt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "bc10c96a-73a7-4c15-fe4e-a7576fa85e23"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "  random_search()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "validation_accuracy: 0.811, train_accuracy: 0.819, settings: [20, 20], -4, -2\n",
            "validation_accuracy: 0.967, train_accuracy: 0.990, settings: [20, 20, 20], -3, -2\n",
            "validation_accuracy: 0.956, train_accuracy: 1.000, settings: [20, 20, 20, 20], -3, -1\n",
            "validation_accuracy: 0.972, train_accuracy: 1.000, settings: [30, 30, 30, 30], -2, -1\n",
            "validation_accuracy: 0.961, train_accuracy: 1.000, settings: [30, 30, 30, 30], -3, -1\n",
            "validation_accuracy: 0.967, train_accuracy: 1.000, settings: [30, 30, 30, 30], -2, -2\n",
            "validation_accuracy: 0.961, train_accuracy: 1.000, settings: [40, 40, 40], -2, -2\n",
            "validation_accuracy: 0.967, train_accuracy: 1.000, settings: [30, 30, 30, 30], -2, 0\n",
            "validation_accuracy: 0.511, train_accuracy: 0.495, settings: [20, 20, 20, 20, 20], -1, -1\n",
            "validation_accuracy: 0.967, train_accuracy: 1.000, settings: [40, 40, 40, 40], -3, -2\n",
            "validation_accuracy: 0.978, train_accuracy: 1.000, settings: [30, 30, 30, 30], -3, -2\n",
            "validation_accuracy: 0.972, train_accuracy: 0.981, settings: [30, 30, 30, 30, 30], -4, -3\n",
            "validation_accuracy: 0.967, train_accuracy: 1.000, settings: [20, 20, 20, 20], -2, -2\n",
            "validation_accuracy: 0.972, train_accuracy: 1.000, settings: [20, 20, 20, 20, 20], -3, -2\n",
            "validation_accuracy: 0.978, train_accuracy: 1.000, settings: [20, 20, 20, 20], -3, -2\n",
            "validation_accuracy: 0.967, train_accuracy: 1.000, settings: [20, 20, 20, 20], -3, -3\n",
            "validation_accuracy: 0.972, train_accuracy: 0.998, settings: [40, 40, 40], -3, -3\n",
            "validation_accuracy: 0.967, train_accuracy: 1.000, settings: [30, 30, 30, 30, 30], -2, -2\n",
            "validation_accuracy: 0.967, train_accuracy: 0.983, settings: [30, 30, 30, 30, 30], -4, -3\n",
            "validation_accuracy: 0.972, train_accuracy: 1.000, settings: [30, 30, 30], -2, -3\n",
            "validation_accuracy: 0.511, train_accuracy: 0.495, settings: [40, 40, 40, 40, 40], -2, -2\n",
            "validation_accuracy: 0.978, train_accuracy: 1.000, settings: [30, 30, 30, 30, 30], -3, -2\n",
            "validation_accuracy: 0.922, train_accuracy: 0.964, settings: [40, 40, 40, 40], -4, -2\n",
            "validation_accuracy: 0.967, train_accuracy: 1.000, settings: [20, 20, 20], -2, -2\n",
            "validation_accuracy: 0.950, train_accuracy: 0.950, settings: [40, 40, 40, 40], -4, -2\n",
            "validation_accuracy: 0.956, train_accuracy: 1.000, settings: [20, 20, 20, 20], -2, -1\n",
            "validation_accuracy: 0.956, train_accuracy: 1.000, settings: [30, 30, 30, 30], -2, -1\n",
            "validation_accuracy: 0.967, train_accuracy: 1.000, settings: [30, 30, 30, 30], -2, -3\n",
            "validation_accuracy: 0.961, train_accuracy: 1.000, settings: [40, 40, 40], -2, -1\n",
            "validation_accuracy: 0.950, train_accuracy: 0.981, settings: [20, 20, 20, 20, 20], -4, -3\n",
            "Best validation_accuracy: 0.9777777777777777\n",
            "Best settings:\n",
            "best_M: 30\n",
            "best_nHidden: 4\n",
            "learning_rate: -3\n",
            "l2: -2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2-ciDIXHTIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}